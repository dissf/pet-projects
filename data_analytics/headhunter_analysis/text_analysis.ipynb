{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40f026b",
   "metadata": {},
   "source": [
    "## 1. Импорты библиотек, инициализация глобальных переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b909a82e",
   "metadata": {},
   "source": [
    "### 1.1 Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8967cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdirt_tongue\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize, ngrams\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# youtube api\n",
    "import googleapiclient.discovery\n",
    "import time\n",
    "import pandas as pd\n",
    "import collections\n",
    "# api для субтитров\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "#text\n",
    "import re\n",
    "import string\n",
    "import pymorphy2\n",
    "import dirt_tongue\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from nltk import word_tokenize, ngrams\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#plt\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "553d1490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.1\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f20c40d",
   "metadata": {},
   "source": [
    "### 1.2 Инициализация глобальных переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_SERVICE_NAME = \"youtube\"\n",
    "API_VERSION = \"v3\"\n",
    "# Ваш API KEY from Google Cloud\n",
    "API_KEY = \"AIzaSyAGJLVT1uUXXGHCV9EdGEshHzokC1KPzkE\"\n",
    "# id канала, с которого нужно собрать информацию о видео\n",
    "# Для примера беру канал вДудь\n",
    "CHANNEL_ID = 'UCMCgOm8GZkHp8zJ6l7_hIuA'\n",
    "youtube = googleapiclient.discovery.build(API_SERVICE_NAME, API_VERSION, developerKey = API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc6833",
   "metadata": {},
   "source": [
    "## 2 Парсинг и предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47160f",
   "metadata": {},
   "source": [
    "### 2.1 Парсинг статистических данных о видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ea64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = youtube.channels().list(\n",
    "       part = \"contentDetails\",\n",
    "       id = CHANNEL_ID,\n",
    "       access_token=API_KEY\n",
    " )\n",
    "resp = r.execute()\n",
    "video_data = {}\n",
    "id_playlist = resp['items'][0]['contentDetails']['relatedPlaylists']['uploads']  \n",
    "id_playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bfea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удобнее всего получить данные о всех видео, собрав все видео в один плейлист\n",
    "# За один запрос можно получить информацию о 5 видео, на момент создания проекта на канале находится 164 видео\n",
    "# Получив первые 5 видео, нужно снова отправить запрос на получение следующих 5 видео\n",
    "# Делаем это, указав свойство 'nextPageToken'\n",
    "video_data = {}\n",
    "next_token = ''\n",
    "while(True):     \n",
    "    time.sleep(0.2)\n",
    "    r = youtube.playlistItems().list(\n",
    "    part=\"contentDetails\",\n",
    "    playlistId = id_playlist,\n",
    "    access_token=API_KEY,\n",
    "    pageToken = next_token\n",
    "    )\n",
    "    tt = r.execute()\n",
    "    resp = r.execute()\n",
    "    for i in resp['items']:\n",
    "        id_videos = i['contentDetails']['videoId']\n",
    "        r = youtube.videos().list(\n",
    "        part=\"snippet, statistics\",\n",
    "        id=id_videos,               \n",
    "        access_token=API_KEY\n",
    "        )\n",
    "        resp1 = r.execute()       \n",
    "        video_data[id_videos] = [CHANNEL_ID,\n",
    "                           resp1['items'][0]['snippet']['publishedAt'],\n",
    "                           resp1['items'][0]['snippet']['title'],\n",
    "                           resp1['items'][0]['snippet']['description'],\n",
    "                           resp1['items'][0]['statistics']['viewCount'],\n",
    "                           resp1['items'][0]['statistics']['likeCount'],\n",
    "                           resp1['items'][0]['statistics']['commentCount']\n",
    "        ]\n",
    "    try:\n",
    "        next_token = resp['nextPageToken']\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f9a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Из собранных данных создаем датафрейм\n",
    "d = {'id': [x for x in video_data],\n",
    "      'channel_id': [video_data[x][0] for x in video_data],\n",
    "      'published_at': [video_data[x][1] for x in video_data],\n",
    "      'title': [video_data[x][2] for x in video_data],\n",
    "      'description': [video_data[x][3] for x in video_data],\n",
    "      'viewCount': [video_data[x][4] for x in video_data],\n",
    "      'likeCount': [video_data[x][5] for x in video_data],\n",
    "      'commentCount': [video_data[x][6] for x in video_data]\n",
    "   }\n",
    "df = pd.DataFrame(d)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f17a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертируем формат даты ('PT2H12M51S') в секунды\n",
    "def convert_YouTube_duration_to_seconds(duration):\n",
    "   day_time = duration.split('T')\n",
    "   day_duration = day_time[0].replace('P', '')\n",
    "   day_list = day_duration.split('D')\n",
    "   if len(day_list) == 2:\n",
    "      day = int(day_list[0]) * 60 * 60 * 24\n",
    "      day_list = day_list[1]\n",
    "   else:\n",
    "      day = 0\n",
    "      day_list = day_list[0]\n",
    "   hour_list = day_time[1].split('H')\n",
    "   if len(hour_list) == 2:\n",
    "      hour = int(hour_list[0]) * 60 * 60\n",
    "      hour_list = hour_list[1]\n",
    "   else:\n",
    "      hour = 0\n",
    "      hour_list = hour_list[0]\n",
    "   minute_list = hour_list.split('M')\n",
    "   if len(minute_list) == 2:\n",
    "      minute = int(minute_list[0]) * 60\n",
    "      minute_list = minute_list[1]\n",
    "   else:\n",
    "      minute = 0\n",
    "      minute_list = minute_list[0]\n",
    "   second_list = minute_list.split('S')\n",
    "   if len(second_list) == 2:\n",
    "      second = int(second_list[0])\n",
    "   else:\n",
    "      second = 0\n",
    "   return day + hour + minute + second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлекаем длительность всех видео в секундах\n",
    "videos = df['id'].tolist()\n",
    "df['duration'] = 0\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    q = youtube.videos().list(\n",
    "        part = 'contentDetails',\n",
    "        id=videos[i],               \n",
    "        access_token=API_KEY\n",
    "        ).execute()\n",
    "    df['duration'][i] = q['items'][0]['contentDetails']['duration']\n",
    "    df['duration'][i] = convert_YouTube_duration_to_seconds(df['duration'][i])\n",
    "df[['duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем удобный формат колонок\n",
    "df = df[['title', 'id', 'published_at', 'description', 'viewCount', 'likeCount', 'commentCount', 'duration']]\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d112592c",
   "metadata": {},
   "source": [
    "### 2.2 Предобработка статистических данных о видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "# Меняем тип данных числовых колонок, так как после парсинга с ютуба все значения формата string(object),\n",
    "# в данном случае необходимо поменять типы колонкам viewCount, likeCount, commentCount, duration на целые числа(int)\n",
    "df = df.astype({'viewCount': int, 'likeCount': int, 'commentCount': int, 'duration': int})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0979b6",
   "metadata": {},
   "source": [
    "* **title** - название видео<br>\n",
    "* **id** - id видео<br>\n",
    "* **published_at** - время и дата публикации видео<br>\n",
    "* **description** - описание видео<br>\n",
    "* **viewCount** - количество просмотров<br>\n",
    "* **likeCount** - количество лайков<br>\n",
    "* **commentCount** - количество комментариев<br>\n",
    "* **duration** - длительность видео в секундах<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712ebbd4",
   "metadata": {},
   "source": [
    "### 2.3 Парсинг субтитров к видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем новый датафрейм для работы с текстом(субтитрами)\n",
    "# Приоритет выбора субтитров: созданные вручную, в случае отсутствия - автоматические\n",
    "# Если субтитров нет - пропускаем\n",
    "df_text = pd.DataFrame()\n",
    "df_text['title'] = df['title']\n",
    "df_text['text'] = ''\n",
    "df_text['dirt_min'] =''\n",
    "df_text['dirt'] =''\n",
    "df_text['total'] =''\n",
    "df_text['uniq'] =''\n",
    "df_text['percent'] =''\n",
    "try:\n",
    "    for i in range(df.shape[0]):\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(df['id'][i])\n",
    "        df_text['text'][i] = transcript_list.find_transcript(['ru']).fetch()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f7fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2d3e9",
   "metadata": {},
   "source": [
    "### 2.4 Преобработка субтитров к видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea7d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stopwords_list = stopwords.words('russian')\n",
    "string.punctuation += '—'\n",
    "# Очищаем текст от символов и ненужных слов\n",
    "def clean_string(text):\n",
    "    text = re.split(' |:|\\.|\\(|\\)|,|\"|;|/|\\n|\\t|-|\\?|\\[|\\]|!', text)\n",
    "    text = ' '.join([word for word in text if word not in string.punctuation])\n",
    "    text = text.lower()\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords_list])\n",
    "    return text\n",
    "# С помощью pymorphy2 приводим слова к начальной форме\n",
    "def string_to_normal_form(string):\n",
    "    string_lst = string.split()\n",
    "    for i in range(len(string_lst)):\n",
    "        string_lst[i] = morph.parse(string_lst[i])[0].normal_form\n",
    "        if (string_lst[i] == 'аду'):\n",
    "            string_lst[i] = 'ад'\n",
    "        if (string_lst[i] == 'рая'):\n",
    "            string_lst[i] = 'рай'\n",
    "    string = ' '.join(string_lst)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c495b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для некоторых видеороликов субтитры отключены/недоступны, поэтому эти видео пропускаем\n",
    "df_text = df_text[df_text.text != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем все субтитры за видео в строку и очиащем текст\n",
    "for j in range(df_text.shape[0]):\n",
    "    s = ''\n",
    "    for i in range(len(df_text['text'][j])):\n",
    "        s = s + string_to_normal_form(clean_string(df_text['text'][j][i]['text'])) + ' '\n",
    "    df_text['text'][j] = s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text.dtypes\n",
    "df_text['duration'] = df.loc[:,['duration']]\n",
    "df_text.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9887aa7",
   "metadata": {},
   "source": [
    "* **title** - название видео<br>\n",
    "* **text** - текст видео из субтитров<br>\n",
    "* **dirt_min** - количество нецензурных слов в минуту<br>\n",
    "* **dirt** - общее количество нецензурных слов<br>\n",
    "* **duration** - длительность видео в секундах<br>\n",
    "* **total** - всего слов в видео<br>\n",
    "* **uniq** - число уникальных слов в видео<br>\n",
    "* **percent** - отношение уникальных слов ко всем<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa76c16",
   "metadata": {},
   "source": [
    "## 3 Работа с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6910d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитываем для каждого видео количество слов в нем, количество уникальных слов и процент уникальных слов относительно общего количества\n",
    "titles = []\n",
    "total = []\n",
    "uniq = []\n",
    "percent = []\n",
    "\n",
    "for title, text in zip(df_text.title, df_text.text):\n",
    "    titles.append(title)\n",
    "    total.append(len(text.split()))\n",
    "    uniq.append(len(set(text.split())))\n",
    "    percent.append(round(len(set(text.split())) / len(text.split()), 2) * 100)\n",
    "df_text.loc[:, ['total']] = total\n",
    "df_text.loc[:, ['uniq']] = uniq\n",
    "df_text.loc[:, ['percent']] = percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0378c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем слова в видео на наличие нецензурной лексики и считаем ее количество\n",
    "detector = dirt_tongue.is_dirt()\n",
    "for j in tqdm(range(df_text.shape[0])):\n",
    "    i = 0\n",
    "    for elem in df_text['text'][j].split():\n",
    "        if detector(elem):\n",
    "            i+=1\n",
    "    df_text['dirt'][j] = i\n",
    "    df_text['dirt_min'][j] = i/df_text['duration'][j]*60\n",
    "df_text = df_text.astype({'dirt_min':float, 'duration' : int, 'dirt': int})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e20de4",
   "metadata": {},
   "source": [
    "## 4 Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a30a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x=\"likeCount\", y=\"commentCount\", color=\"viewCount\", \n",
    "                 hover_name=\"title\", size = 'viewCount', \n",
    "                 title = 'Распределение видеороликов по количеству комментариев, лайков и просмотрам')\n",
    "fig.show(\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acba9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем облако слов для последних 12 видео\n",
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.4)\n",
    "i = 1\n",
    "for title, text in zip(df_text.head(12).title, df_text.head(12).text):\n",
    "    tokens = word_tokenize(text)\n",
    "    text_raw = \" \".join(tokens)\n",
    "    wordcloud = WordCloud(colormap='PuBu', background_color='white', contour_width=10).generate(text_raw)\n",
    "    plt.subplot(4, 3, i, label=title,frame_on=True)\n",
    "    plt.tick_params(labelsize=10)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f'{title[:30]}...',fontdict={'fontsize':7,'color':'grey'},y=0.93)\n",
    "    plt.tick_params(labelsize=10)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d8d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Топ-5 видео с наименьшим содержанием нецензурной лексики\n",
    "\n",
    "df_text.sort_values(by='dirt_min', ascending = False).tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a416c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_text, x=\"total\", y=\"dirt_min\", color=\"dirt_min\", \n",
    "                 hover_name=\"title\", size = 'total', \n",
    "                 title = 'Отношение количества нецензурный слов в минуту к общему количеству слов')\n",
    "fig.show(\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fdd61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_text.sort_values(by='dirt_min').tail(10), x=\"total\", y=\"dirt\", color=\"dirt\", \n",
    "                 hover_name=\"title\", size = 'total', \n",
    "                 title = 'Отношение количества нецензурный слов к общему количеству слов для топ 10 видео с наибольшим содержанием нецензурной лексики')\n",
    "fig.show(\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ca39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_text, x=\"dirt\", title = 'Распределение по количеству нецензурных слов к количеству видео')\n",
    "fig.show(\"png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
